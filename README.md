 In this project, a support vector machine (SVM) is selected as the classification model. The SVM identifies an optimal hyperplane in a high-dimensional space, which effectively separates the samples of different classes. Maximizing the classification interval results in enhanced generalization ability. The use of kernel functions (e.g., polynomial kernel, RBF kernel function) enables SVM to identify a nonlinear decision boundary in instances where the input data is nonlinearly differentiable. The task comprises a total of only 100 audio files, which is a relatively small data set. SVM performs well in such cases because it focuses on the support vectors (samples that are close to the decision boundaries) rather than on all the samples. SVM avoids overfitting by controlling the classification intervals in small sample and high-dimensionality cases.
    In the case of dividing a 30-second audio file into two 15-second audio files, The precise methodology for splitting the data will be elucidated in greater detail once the dataset has been constructed. In addition to the two parameter-independent SVMs that determine the probability of an audio feature belonging to a true story versus a false story, a model is required that fuses the outputs of the two SVMs to provide the final classification result. In this project, logistic regression is employed as the model that integrates the two SVM outputs to generate the final prediction results. In other words, the positive class probabilities of the SVM outputs will be spliced into a new feature vector, which will then be used as input to the logistic regression model. The logistic regression model is relatively simple, easy to understand, implement, and interpret. It is an extension of the linear model that utilizes probabilistic functions (e.g., sigmoid functions) to map linear combinations to category labels, which is highly intuitive. This task is a binary categorization task, and logistic regression is particularly well suited for binary categorization tasks.
